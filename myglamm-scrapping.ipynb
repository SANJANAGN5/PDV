{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP/iJlW55mduc6jZhiZhv0e"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dBzANmW0cJ7m","executionInfo":{"status":"ok","timestamp":1756098904778,"user_tz":-330,"elapsed":11799,"user":{"displayName":"Sanjana G N","userId":"16922873160080587760"}},"outputId":"d95c6dae-25ac-416b-e081-bf83506cdbfa"},"outputs":[{"output_type":"stream","name":"stdout","text":["Scraped 20 products\n","CSV saved to glam_products.csv\n","JSON saved to glam_products.json\n"]}],"source":["# Installing dependencies (uncomment if running in a fresh environment)\n","# !apt-get update > /dev/null\n","# !apt-get install -y firefox geckodriver > /dev/null\n","# !pip install selenium beautifulsoup4 > /dev/null\n","\n","import os\n","import csv\n","import json\n","import time\n","from selenium import webdriver\n","from selenium.webdriver.firefox.options import Options\n","from bs4 import BeautifulSoup\n","\n","# Set DISPLAY env for headless mode (optional in most cases)\n","os.environ['DISPLAY'] = ':0'\n","\n","# Firefox options for headless mode\n","options = Options()\n","options.add_argument('--headless')\n","options.add_argument('--disable-gpu')\n","options.add_argument('--window-size=1920,1080')\n","\n","# Start Selenium WebDriver\n","driver = webdriver.Firefox(options=options)\n","\n","# URL of Blinkit Dairy, Bread & Eggs section (replace with actual URL)\n","url = \"https://www.nykaa.com/brands/myglamm/c/6883\"  # <-- Update to real URL\n","driver.get(url)\n","time.sleep(5)  # Wait for JS to load content\n","\n","# Get page source and parse with BeautifulSoup\n","html = driver.page_source\n","soup = BeautifulSoup(html, \"html.parser\")\n","driver.quit()\n","\n","# Find all product cards (adjust the selector based on actual Blinkit page structure)\n","product_cards = soup.find_all(\"div\", class_=\"productWrapper css-17nge1h\")\n","\n","\n","products = []\n","for item in product_cards:\n","    title_tag = item.find(\"div\", class_=\"css-xrzmfa\")\n","    price_tag = item.find(\"span\", class_=\"css-111z9ua\")\n","    ratings_tag = item.find(\"span\", class_=\"css-1qbvrhp\")\n","\n","    title = title_tag.text.strip() if title_tag else \"No title\"\n","    price = price_tag.text.strip() if price_tag else \"No price\"\n","    ratings = ratings_tag.text.strip() if ratings_tag else \"No rating\"\n","\n","    products.append({\n","        \"title\": title,\n","        \"price\": price,\n","        \"ratings\": ratings\n","    })\n","\n","#Save products to CSV file\n","csv_file = \"glam_products.csv\"\n","with open(csv_file, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n","    writer = csv.DictWriter(f, fieldnames=[\"title\", \"price\", \"ratings\"])\n","    writer.writeheader()\n","    writer.writerows(products)\n","\n","# Save products to JSON file\n","json_file = \"glam_products.json\"\n","with open(json_file, \"w\", encoding=\"utf-8\") as f:\n","    json.dump(products, f, indent=2)\n","\n","print(f\"Scraped {len(products)} products\")\n","print(f\"CSV saved to {csv_file}\")\n","print(f\"JSON saved to {json_file}\")\n","\n"]}]}